<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Progetto SQL</title>
    <link rel="stylesheet" href="stile.css">
</head>
<body>
    <header>
        <h1>Progetto SQL - Unione di più dataset </h1>
    </header>
    <section>
        <!-- Esempio di una card per un progetto -->
        <div class="card">
            <h2>Riassunto</h2>
            <p>In questo progetto, l'obiettivo era unire più dataset scaricati dalla piattaforma Kaggle tramite una query in linguaggio SQL. 
                Per fare ciò, abbiamo innanzitutto creato il database e successivamente importato le tabelle dai vari file .csv. 
                Le eventuali funzioni implementate sono state utilizzate per correggere i difetti che sono stati riscontrati al momento dell'implementazione della query,  come ad esempio il fatto che una tabella utilizzava come data di 
                uscita l'intera data, mentre il resto dei dataset riportava solo l'anno.
                Il risultato principale è stato l'aggregazione delle informazioni presenti in più dataset, creando un dataset più ricco di informazioni, utile per una successiva 
                fase di esplorazione più approfondita. Viene riportato qui sotto il codice utilizzato:</p>
            <p style="color:red">
                from dateutil.parser import parse
                import csv, sqlite3
                
                def fix_title(title):
                    if ',' in title:
                        parts = title.split(', ')
                        if len(parts) == 2:
                            title = parts[1] + ' ' + parts[0]
                    return title
                
                def extract_year(date_str):
                    try:
                        parsed_date = parse(date_str)
                        return str(parsed_date.year)
                    except ValueError:
                        return None
                
                con = sqlite3.connect("Movie.db")
                cur = con.cursor()
                
                cur.execute("DROP TABLE Movie1;")
                cur.execute("DROP TABLE Movie2;")
                cur.execute("DROP TABLE Movie3;")
                cur.execute("DROP TABLE Movie4;")
                
                
                cur.execute("CREATE TABLE Movie1 (budget, genres, homepage, keywords, original_language, original_title, overview, popularity, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, vote_average, vote_count);")
                cur.execute("CREATE TABLE Movie2 (name, rating, genre, year, released, score, votes, director, writer, star, country, budget, gross, company, runtime);")
                cur.execute("CREATE TABLE Movie3 (Poster_Link, Series_Title, Released_Year, Certificate, Runtime, Genre, IMDB_Rating, Overview, Meta_score, Director, Star1, Star2, Star3, Star4, No_of_Votes, Gross);")
                cur.execute("CREATE TABLE Movie4 (title, year, bechdelRating, imdbAverageRating, numVotes, runtimeMinutes, genre1, genre2, genre3);")
                
                
                def load_data(csv_file, table_name, columns):
                    with open(csv_file, 'r', encoding='utf-8') as fin:
                        dr = csv.DictReader(fin)
                        to_db = []
                        for i in dr:
                            fixed_row = []
                            for col in columns:
                                if col == 'title':
                                    fixed_row.append(fix_title(i[col]))
                                elif col == 'release_date':
                                    fixed_row.append(extract_year(i['release_date'])) 
                                else:
                                    fixed_row.append(i[col])
                            to_db.append(tuple(fixed_row))
                
                    cur.executemany(f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['?']*len(columns))});", to_db)
                    con.commit()
                
                load_data('/content/tmdb_5000_movies.csv', 'Movie1', ["budget", "genres", "homepage", "keywords", "original_language", "original_title", "overview", "popularity", "production_companies", "production_countries", "release_date", "revenue", "runtime", "spoken_languages", "status", "tagline", "title", "vote_average", "vote_count"])
                load_data('/content/movies.csv', 'Movie2', ["name", "rating", "genre", "year", "released", "score", "votes", "director", "writer", "star", "country", "budget", "gross", "company", "runtime"])
                load_data('/content/imdb_top_1000.csv', 'Movie3', ["Poster_Link", "Series_Title", "Released_Year", "Certificate", "Runtime", "Genre", "IMDB_Rating", "Overview", "Meta_score", "Director", "Star1", "Star2", "Star3", "Star4", "No_of_Votes", "Gross"])
                load_data('/content/Bechdel_IMDB_Merge0524.csv', 'Movie4', ["title", "year", "bechdelRating", "imdbAverageRating", "numVotes", "runtimeMinutes", "genre1", "genre2", "genre3"])
                con.close()

                import pandas as pd
                con = sqlite3.connect("Movie.db")
                query = """
                SELECT *
                FROM Movie4 m4
                LEFT JOIN Movie3 m3 ON m4.title = m3.Series_Title AND m4.year = m3.Released_Year
                LEFT JOIN Movie2 m2 ON m4.title = m2.name AND m4.year = m2.year
                LEFT JOIN Movie1 m1 ON m4.title = m1.title AND m4.year = m1.release_date ;
                """
                
                df = pd.read_sql_query(query, con)
                
                con.close()

                df.head()

                df.to_csv("Movies_Combined.csv", index=False, encoding='utf-8-sig')
                
                print("Dati esportati con successo in 'Movies_Combined.csv'")
                </p>
            
        </div>
        <!-- Ripeti per altri progetti -->
    </section>
</body>
</html>
